{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "# from DataLoader import Loader, configure_for_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader(object):\n",
    "    def __init__(self, root, shuffle=True):\n",
    "        self.root = root\n",
    "        A_folders = glob.glob(f'{root}/live/*')\n",
    "        B_folders = glob.glob(f'{root}/live/*')\n",
    "\n",
    "        def shuffle_list(A, B):\n",
    "            random.shuffle(A)\n",
    "            for i in range(len(A)):\n",
    "                if A[i] == B[i]:\n",
    "                    shuffle_list(A, B)\n",
    "            return A\n",
    "\n",
    "        A_imgs = []\n",
    "        B_imgs = []\n",
    "        for i in range(len(A_folders)):\n",
    "            A = glob.glob(f'{A_folders[i]}/*.png')\n",
    "            B = glob.glob(f'{B_folders[i]}/*.png')\n",
    "\n",
    "            if shuffle:\n",
    "                A = shuffle_list(A, B)\n",
    "            A_imgs = A_imgs + A\n",
    "            B_imgs = B_imgs + B\n",
    "            \n",
    "        self.A_imgs = np.array(A_imgs)\n",
    "\n",
    "#         self.A_ds = tf.data.Dataset.from_tensor_slices(A_imgs)\n",
    "#         self.B_ds = tf.data.Dataset.from_tensor_slices(B_imgs)\n",
    "\n",
    "\n",
    "    def decode_img(self, img_path):\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_png(img, 3)\n",
    "        img = tf.image.resize(img, [56, 56])\n",
    "        img = (img - 127.5) / 127.5\n",
    "\n",
    "        return img\n",
    "\n",
    "    def load(self):\n",
    "        A_ds = tf.data.Dataset.from_tensor_slices(self.A_imgs)\n",
    "        A_ds = A_ds.map(self.decode_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#         B_ds = self.B_ds.map(self.decode_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        ds = tf.data.Dataset.zip((A_ds))\n",
    "\n",
    "        return ds\n",
    "\n",
    "\n",
    "def configure_for_performance(ds, cnt, batchz, shuffle=False):\n",
    "    if shuffle==True:\n",
    "        ds = ds.shuffle(buffer_size=cnt)\n",
    "        ds = ds.batch(batchz)\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    elif shuffle==False:\n",
    "        ds = ds.batch(batchz)\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 14, 14, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 28, 28, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 56, 56, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 56, 56, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 56, 56, 3)         3459      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 56, 56, 3)         0         \n",
      "=================================================================\n",
      "Total params: 1,768,387\n",
      "Trainable params: 1,761,347\n",
      "Non-trainable params: 7,040\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "random_input = tf.keras.layers.Input(shape=100)\n",
    "\n",
    "x = tf.keras.layers.Dense(64 * 7 * 7)(random_input)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tf.keras.layers.Reshape((7, 7, 64))(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=(5,5), strides=(2,2), padding='same')(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=(5,5), strides=(2,2), padding='same')(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=(5,5), strides=(2,2), padding='same')(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=(5,5), padding='same')(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=3, kernel_size=(3,3), padding='same')(x)\n",
    "generated_image = tf.keras.layers.Activation('tanh')(x)\n",
    "\n",
    "generator = tf.keras.models.Model(inputs=random_input, outputs=generated_image)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 56, 56, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 128)       9728      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 14, 14, 64)        204864    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 7, 7, 64)          204864    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 3, 3, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 1, 1, 64)          73792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 1, 1, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 904,961\n",
      "Trainable params: 904,065\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_input = tf.keras.layers.Input(shape=(56, 56, 3))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=128, kernel_size=(5,5), strides=2, padding='same')(image_input)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), strides=2, padding='same')(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=128, kernel_size=(5,5), strides=2, padding='same')(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same')(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=128, kernel_size=(5,5))(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3))(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "real_vs_fake_output = tf.keras.layers.Activation('sigmoid')(x)\n",
    "\n",
    "discriminator = tf.keras.models.Model(inputs=image_input, outputs=real_vs_fake_output)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24ff1238370>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.49997735]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_optim = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "gen_optim = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rel_disc_loss(disc_r, disc_f):\n",
    "#     epsilon=0.000001\n",
    "#     return -(K.mean(K.log(K.sigmoid(disc_r - K.mean(disc_f, axis=0))+epsilon), axis=0)\n",
    "#              +K.mean(K.log(1-K.sigmoid(disc_f - K.mean(disc_r, axis=0))+epsilon), axis=0))\n",
    "\n",
    "# def rel_gen_loss(disc_r, disc_f):\n",
    "#     epsilon=0.000001\n",
    "#     return -(K.mean(K.log(K.sigmoid(disc_f - K.mean(disc_r, axis=0))+epsilon), axis=0)\n",
    "#              +K.mean(K.log(1-K.sigmoid(disc_r - K.mean(disc_f, axis=0))+epsilon), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ZipDataset shapes: (56, 56, 3), types: tf.float32>\n"
     ]
    }
   ],
   "source": [
    "root = 'E:/Iris_dataset/nd_labeling_iris_data/Cycle_PNG/1-fold/A'\n",
    "ds = Loader(root, shuffle=True).load()\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([batch_size, 100])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(gen_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    gen_optim.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    disc_optim.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'E:/backup/ckp/GAN/rasgan/1/ckp'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=gen_optim,\n",
    "                                 discriminator_optimizer=disc_optim,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------now epoch : 0---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 1---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 2---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 3---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 4---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 5---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 6---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 7---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 8---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 9---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 10---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 11---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 12---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 13---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 14---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 15---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 16---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 17---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 18---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 19---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 20---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 21---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 22---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 23---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 24---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 25---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 26---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 27---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 28---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 29---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 30---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 31---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 32---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 33---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 34---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 35---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 36---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 37---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 38---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 39---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 40---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 41---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 42---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 43---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 44---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 45---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 46---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 47---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 48---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 49---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 50---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 51---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 52---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 53---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 54---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 55---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 56---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 57---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 58---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 59---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 60---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 61---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 62---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 63---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 64---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 65---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 66---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 67---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 68---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 69---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 70---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 71---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 72---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 73---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 74---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 75---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 76---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 77---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 78---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 79---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 80---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 81---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 82---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 83---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 84---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 85---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 86---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 87---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 88---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 89---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 90---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 91---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 92---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 93---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 94---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 95---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 96---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 97---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 98---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 99---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 100---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 101---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 102---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 103---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 104---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 105---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 106---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 107---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 108---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 109---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 110---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 111---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 112---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 113---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 114---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 115---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 116---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 117---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 118---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 119---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 120---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 121---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 122---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 123---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 124---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 125---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 126---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 127---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 128---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 129---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 130---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 131---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 132---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 133---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 134---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 135---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 136---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 137---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n",
      "---------------now step: 2277/2000---------------\n",
      "---------------now epoch : 138---------------\n",
      "---------------now step: 2277/0---------------\n",
      "---------------now step: 2277/1000---------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-495c778755d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'---------------now epoch : {epoch}---------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_it\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mgen_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    745\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[1;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[0;32m    731\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   2571\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2572\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2573\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   2574\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"IteratorGetNext\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2575\u001b[0m         \"output_shapes\", output_shapes)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "batch_size = 2\n",
    "cnt = 4554\n",
    "noise_size = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ds_shuffle = configure_for_performance(ds, cnt, batch_size)\n",
    "    ds_it = iter(ds_shuffle)\n",
    "    print(f'---------------now epoch : {epoch}---------------')\n",
    "    for step in range(cnt//batch_size):\n",
    "        img = next(ds_it)\n",
    "        \n",
    "        gen_img = train_step(img)\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            img = np.array(gen_img[0])\n",
    "            img = img * 127.5 + 127.5\n",
    "            cv2.imwrite(f'E:/backup/ckp/GAN/rasgan/1/sample/generate_img_{epoch}_{step}.png', img)\n",
    "            \n",
    "        if step % 1000 == 0:\n",
    "            print(f'---------------now step: {cnt//2}/{step}---------------')\n",
    "    \n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
